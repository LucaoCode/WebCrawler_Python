# 游돚Projeto Web Crawler - Vagas de Emprego no ES

Este projeto realiza o web scraping do site TrabalhaES para extrair vagas de emprego dispon칤veis na cidade de Vit칩ria, ES. O resultado 칠 salvo em um arquivo CSV e enviado por e-mail automaticamente.

## 游끵 Funcionalidades

- Extra칞칚o de vagas de emprego do site *www.trabalhaes.com.br*
- Armazenamento de dados em arquivo CSV
- Envio autom치tico do arquivo gerado por e-mail
- Executa rotinas peri칩dicas

## 游삐 Apresenta칞칚o do Projeto

**Video em Breve**

## 游동 Tecnologias utilizadas

- **Python 3**
- **Scrapy** - Biblioteca de scraping para realizar a extra칞칚o de dados.
- **Requests** - Para fazer requisi칞칫es HTTP
- **smtplib** - Para envio de e-mails via protocolo SMTP.
- **email.mime** - Para estrutura칞칚o e envio do e-mail com anexo.
- **Agendador de Tarefas do Windows** - Para agendamento de execu칞칫es autom치ticas do script.

## 游뱄 Requisitos

1. Python 3.9 ou superior instalado.
2. Instalar as bibliotecas necess치rias no terminal:
```python
pip install scrapy requests
```
3. Acesso a uma conta de e-mail com senha de app configurada para envio via SMTP (usado para enviar o relat칩rio).

## 游쬒omo Executar

### 1. Rodar o scrapy

- Para iniciar o processo de scraping, execute o comando no terminal:
```python
scrapy crawl CrawlVagas
```
sso iniciar치 o crawler que extrair치 as vagas e criar치 um arquivo CSV com o relat칩rio na pasta *Relatorio*.

### 2. Envio do relat칩tio para o E-mail

- No c칩digo Python, ajuste os campos de *remetente*, *destinatario* e *senha* de acordo com suas credenciais de e-mail.

- Ap칩s a extra칞칚o das vagas, o script automaticamente enviar치 o relat칩rio gerado para o destinat치rio configurado no c칩digo.

- Certifique-se de usar uma senha de aplicativo do Gmail, configurada via painel de seguran칞a.

### 3. Exemplo de arquivo CSV gerado

O arquivo gerado ter치 o seguinte formato:
```python
Vaga;Data;Link
Desenvolvedor Python;2024-10-10;https://www.trabalhaes.com.br/vaga/12345
Analista de Dados;2024-10-11;https://www.trabalhaes.com.br/vaga/12346
```
### 4. Automa칞칚o com Crontab (Linux/Mac)

- Para rodar o script automaticamente em um intervalo de tempo, adicione uma tarefa no Crontab. Exemplo para rodar diariamente 맙 9h:
```bash
0 9 * * * cd /caminho/para/o/projeto && scrapy crawl CrawlVagas
```
### 5. Automa칞칚o no Windows (Agendador de tarefas)

- Para rodar automaticamente no Windows, use o Agendador de Tarefas. Crie uma tarefa para executar o arquivo *rodar.bat* configurado para iniciar o Scrapy.

## 游뱔 Respons치veis pelo projeto

[Lucas Lima Campos](https://www.linkedin.com/in/lucaslimacampos/)